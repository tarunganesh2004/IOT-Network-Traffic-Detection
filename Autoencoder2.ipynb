{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cleaned_data2_iotid23.csv\")  # Replace with actual dataset\n",
    "X = df.drop(columns=[\"Label\"])\n",
    "y = df[\"Label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of infinite values in X: 1830\n",
      "Number of NaN values in X: 1830\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Check for infinite values\n",
    "print(\"Number of infinite values in X:\", np.isinf(X).sum().sum())\n",
    "\n",
    "# Replace infinite values with NaN (if any)\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Check for NaN values\n",
    "print(\"Number of NaN values in X:\", X.isna().sum().sum())\n",
    "\n",
    "# Fill or drop NaN values\n",
    "X.fillna(X.median(), inplace=True)  # Replace NaN with median values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle class imbalance using SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    "# )\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler (better for small samples)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Autoencoder model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "input_dim = X_train.shape[1]\n",
    "autoencoder = Sequential(\n",
    "    [\n",
    "        Dense(64, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(input_dim, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, X_test),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Extract learned features\n",
    "encoder = Model(autoencoder.input, autoencoder.layers[1].output)\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_test_encoded = encoder.predict(X_test)\n",
    "\n",
    "# Train XGBoost on encoded features\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "xgb_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_model.predict(X_test_encoded)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(\n",
    "    y_test, xgb_model.predict_proba(X_test_encoded)[:, 1], pos_label=1\n",
    ")\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(\n",
    "    y_test, xgb_model.predict_proba(X_test_encoded)[:, 1], pos_label=1\n",
    ")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Autoencoder Model with Weighted Loss\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 16\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "decoded = Dense(input_dim, activation=\"sigmoid\")(encoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "\n",
    "# Weighted Loss Function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    weights = np.where(y_true == 1, 10, 1)  # Give more weight to minority class\n",
    "    return keras.losses.mean_squared_error(y_true, y_pred) * weights\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer=\"adam\", loss=custom_loss)\n",
    "autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_test, X_test),\n",
    ")\n",
    "\n",
    "# Feature extraction\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_test_encoded = encoder.predict(X_test)\n",
    "\n",
    "# Calculate class weights for XGBoost\n",
    "unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "total_samples = len(y_train)\n",
    "class_weights = {\n",
    "    cls: total_samples / (len(unique_classes) * count)\n",
    "    for cls, count in zip(unique_classes, class_counts)\n",
    "}\n",
    "\n",
    "# XGBoost Model with Class Weights\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(unique_classes),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    scale_pos_weight=[\n",
    "        class_weights[cls] for cls in unique_classes\n",
    "    ],  # Apply class weights\n",
    ")\n",
    "xgb_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_model.predict(X_test_encoded)\n",
    "y_pred_prob = xgb_model.predict_proba(X_test_encoded)\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(unique_classes)):\n",
    "    fpr, tpr, _ = roc_curve(y_test == i, y_pred_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"Class {i} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(unique_classes)):\n",
    "    precision, recall, _ = precision_recall_curve(y_test == i, y_pred_prob[:, i])\n",
    "    plt.plot(recall, precision, label=f\"Class {i}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save Models\n",
    "encoder.save(\"autoencoder_encoder.h5\")\n",
    "xgb_model.save_model(\"xgboost_model.json\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"Models saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
